{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2e500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf96ce",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes (GNB) is a **generative probabilistic model** for **continuous features**. Let the dataset be:\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = {(x_i, y_i)}_{i=1}^n, \\quad x_i \\in \\mathbb{R}^m, \\ y_i \\in {1, \\dots, K}\n",
    "$$\n",
    "\n",
    "Then:\n",
    "\n",
    "1. **Naive Bayes assumption**: each feature is independent given the class:\n",
    "$$\n",
    "P(x \\mid y=c) = \\prod_{j=1}^m P(x_j \\mid y=c)\n",
    "$$\n",
    "\n",
    "2. **Gaussian distribution**: each feature (x_j) is normally distributed conditioned on the class (y=c):\n",
    "$$\n",
    "x_j \\mid y=c \\sim \\mathcal{N}(\\mu_{jc}, \\sigma^2_{jc})\n",
    "$$\n",
    "\n",
    "So the **conditional probability density function** is:\n",
    "\n",
    "$$\n",
    "P(x_j \\mid y=c) = \\frac{1}{\\sqrt{2\\pi \\sigma^2_{jc}}} \\exp\\Bigg(-\\frac{(x_j - \\mu_{jc})^2}{2 \\sigma^2_{jc}}\\Bigg)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b566e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNB(object):\n",
    "    def fit(self, X, y):\n",
    "        '''Parameter estimation for Gaussian NB'''\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        self._classes = np.unique(y)\n",
    "        n_classes = len(self._classes)\n",
    "\n",
    "        # Initialise mean, var, and prior for each class.\n",
    "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._priors = np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "        for idx, c in enumerate(self._classes):\n",
    "\n",
    "            #Get examples with label y=c\n",
    "            X_c = X[y == c]\n",
    "\n",
    "            #Estimate mean from the training examples of class c.\n",
    "            self._mean[idx, :] = X_c.mean(axis=0)\n",
    "\n",
    "            #Estimate variance from the training examples of class c.\n",
    "            self._var[idx, :] = X_c.var(axis=0)\n",
    "\n",
    "            #Estimate priors.\n",
    "            self._priors[idx] = X_c.shape[0] / float(n_samples)\n",
    "\n",
    "        print(\"Mean: \", self._mean)\n",
    "        print(\"Variance: \", self._var)\n",
    "        print(\"Priors: \", self._priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c063c26",
   "metadata": {},
   "source": [
    "### Parameter Estimation\n",
    "\n",
    "For each class (c):\n",
    "\n",
    "* **Mean**:\n",
    "\n",
    "$$\n",
    "\\mu_{jc} = \\frac{1}{N_c} \\sum_{i:y_i=c} x_{ij}\n",
    "$$\n",
    "\n",
    "* **Variance**:\n",
    "\n",
    "$$\n",
    "\\sigma^2_{jc} = \\frac{1}{N_c} \\sum_{i:y_i=c} (x_{ij} - \\mu_{jc})^2\n",
    "$$\n",
    "\n",
    "* **Class prior**:\n",
    "\n",
    "$$\n",
    "\\pi_c = P(y=c) = \\frac{N_c}{n}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04789c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNB(object):\n",
    "    def fit(self, X, y):\n",
    "        '''Parameter estimation for Gaussian NB'''\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        self._classes = np.unique(y)\n",
    "        n_classes = len(self._classes)\n",
    "\n",
    "        # Initialise mean, var, and prior for each class.\n",
    "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._priors = np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "        for idx, c in enumerate(self._classes):\n",
    "\n",
    "            #Get examples with label y=c\n",
    "            X_c = X[y == c]\n",
    "\n",
    "            #Estimate mean from the training examples of class c.\n",
    "            self._mean[idx, :] = X_c.mean(axis=0)\n",
    "\n",
    "            #Estimate variance from the training examples of class c.\n",
    "            self._var[idx, :] = X_c.var(axis=0)\n",
    "\n",
    "            #Estimate priors.\n",
    "            self._priors[idx] = X_c.shape[0] / float(n_samples)\n",
    "\n",
    "        print(\"Mean: \", self._mean)\n",
    "        print(\"Variance: \", self._var)\n",
    "        print(\"Priors: \", self._priors)\n",
    "\n",
    "    def _calc_pdf(self, class_idx, X):\n",
    "        '''Calculates probability density for samples for class label class_idx'''\n",
    "\n",
    "        mean = self._mean[class_idx]\n",
    "        var = np.diag(self._var[class_idx])\n",
    "        z = np.power(2 * np.pi, X.shape[0]/2) * np.power(np.linalg.det(var), 1/2)\n",
    "        return (1/z) * np.exp(-(1/2)*(X - mean).T @ (np.linalg.inv(var)) @ (X - mean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be981c6",
   "metadata": {},
   "source": [
    "### Likelihood of a Sample\n",
    "\n",
    "Assuming independence between features:\n",
    "\n",
    "$$\n",
    "P(x \\mid y=c) = \\prod_{j=1}^m P(x_j \\mid y=c) = \\prod_{j=1}^m \\frac{1}{\\sqrt{2\\pi \\sigma^2_{jc}}} \\exp\\Big(-\\frac{(x_j - \\mu_{jc})^2}{2 \\sigma^2_{jc}}\\Big)\n",
    "$$\n",
    "\n",
    "In log-space\n",
    "\n",
    "$$\n",
    "\\log P(x \\mid y=c) = \\sum_{j=1}^m \\Big [-\\frac{1}{2}\\log(2\\pi \\sigma^2_{jc}) - \\frac{(x_j - \\mu_{jc})^2}{2\\sigma^2_{jc}} \\Big]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b547c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNB(object):\n",
    "    def fit(self, X, y):\n",
    "        '''Parameter estimation for Gaussian NB'''\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        self._classes = np.unique(y)\n",
    "        n_classes = len(self._classes)\n",
    "\n",
    "        # Initialise mean, var, and prior for each class.\n",
    "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._priors = np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "        for idx, c in enumerate(self._classes):\n",
    "\n",
    "            #Get examples with label y=c\n",
    "            X_c = X[y == c]\n",
    "\n",
    "            #Estimate mean from the training examples of class c.\n",
    "            self._mean[idx, :] = X_c.mean(axis=0)\n",
    "\n",
    "            #Estimate variance from the training examples of class c.\n",
    "            self._var[idx, :] = X_c.var(axis=0)\n",
    "\n",
    "            #Estimate priors.\n",
    "            self._priors[idx] = X_c.shape[0] / float(n_samples)\n",
    "\n",
    "        print(\"Mean: \", self._mean)\n",
    "        print(\"Variance: \", self._var)\n",
    "        print(\"Priors: \", self._priors)\n",
    "\n",
    "    def _calc_pdf(self, class_idx, X):\n",
    "        '''Calculates probability density for samples for class label class_idx'''\n",
    "\n",
    "        mean = self._mean[class_idx]\n",
    "        var = np.diag(self._var[class_idx])\n",
    "        z = np.power(2 * np.pi, X.shape[0]/2) * np.power(np.linalg.det(var), 1/2)\n",
    "        return (1/z) * np.exp(-(1/2)*(X - mean).T @ (np.linalg.inv(var)) @ (X - mean))\n",
    "\n",
    "    def _calc_prod_likelihood_prior(self, X):\n",
    "        '''Calculates product of likelihood and priors.'''\n",
    "\n",
    "        self._prod_likelihood_prior = np.zeros((X.shape[0], len(self._classes)), dtype=np.float64)\n",
    "\n",
    "        for x_idx, x in enumerate(X):\n",
    "            for idx, c in enumerate(self._classes):\n",
    "                self._prod_likelihood_prior[x_idx, c] = (np.log(self._calc_pdf(idx, x)) + np.log(self._priors[idx]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a6e364",
   "metadata": {},
   "source": [
    "### Posterior Probability\n",
    "\n",
    "By Bayesâ€™ theorem:\n",
    "\n",
    "$$\n",
    "P(y=c \\mid x) = \\frac{P(x \\mid y=c) \\pi_c}{\\sum_{c'=1}^K P(x \\mid y=c') \\pi_{c'}}\n",
    "$$\n",
    "\n",
    "* `_calc_prod_likelihood_prior(X)` computes (\\log P(x \\mid y=c) + \\log \\pi_c) for each class.\n",
    "* `predict_proba(X)` converts log-likelihoods to probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNB(object):\n",
    "    def fit(self, X, y):\n",
    "        '''Parameter estimation for Gaussian NB'''\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        self._classes = np.unique(y)\n",
    "        n_classes = len(self._classes)\n",
    "\n",
    "        # Initialise mean, var, and prior for each class.\n",
    "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._priors = np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "        for idx, c in enumerate(self._classes):\n",
    "\n",
    "            #Get examples with label y=c\n",
    "            X_c = X[y == c]\n",
    "\n",
    "            #Estimate mean from the training examples of class c.\n",
    "            self._mean[idx, :] = X_c.mean(axis=0)\n",
    "\n",
    "            #Estimate variance from the training examples of class c.\n",
    "            self._var[idx, :] = X_c.var(axis=0)\n",
    "\n",
    "            #Estimate priors.\n",
    "            self._priors[idx] = X_c.shape[0] / float(n_samples)\n",
    "\n",
    "        print(\"Mean: \", self._mean)\n",
    "        print(\"Variance: \", self._var)\n",
    "        print(\"Priors: \", self._priors)\n",
    "\n",
    "    def _calc_pdf(self, class_idx, X):\n",
    "        '''Calculates probability density for samples for class label class_idx'''\n",
    "\n",
    "        mean = self._mean[class_idx]\n",
    "        var = np.diag(self._var[class_idx])\n",
    "        z = np.power(2 * np.pi, X.shape[0]/2) * np.power(np.linalg.det(var), 1/2)\n",
    "        return (1/z) * np.exp(-(1/2)*(X - mean).T @ (np.linalg.inv(var)) @ (X - mean))\n",
    "\n",
    "    def _calc_prod_likelihood_prior(self, X):\n",
    "        '''Calculates product of likelihood and priors.'''\n",
    "\n",
    "        self._prod_likelihood_prior = np.zeros((X.shape[0], len(self._classes)), dtype=np.float64)\n",
    "\n",
    "        for x_idx, x in enumerate(X):\n",
    "            for idx, c in enumerate(self._classes):\n",
    "                self._prod_likelihood_prior[x_idx, c] = (np.log(self._calc_pdf(idx, x)) + np.log(self._priors[idx]))\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''Predicts class labels for each example'''\n",
    "        \n",
    "        self._calc_prod_likelihood_prior(X)\n",
    "\n",
    "        return np.argmax(self._prod_likelihood_prior, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2244a80",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "The predicted class is the one with the **highest posterior probability**:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\arg\\max_c P(y=c \\mid x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf4917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNB(object):\n",
    "    def fit(self, X, y):\n",
    "        '''Parameter estimation for Gaussian NB'''\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        self._classes = np.unique(y)\n",
    "        n_classes = len(self._classes)\n",
    "\n",
    "        # Initialise mean, var, and prior for each class.\n",
    "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
    "        self._priors = np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "        for idx, c in enumerate(self._classes):\n",
    "\n",
    "            #Get examples with label y=c\n",
    "            X_c = X[y == c]\n",
    "\n",
    "            #Estimate mean from the training examples of class c.\n",
    "            self._mean[idx, :] = X_c.mean(axis=0)\n",
    "\n",
    "            #Estimate variance from the training examples of class c.\n",
    "            self._var[idx, :] = X_c.var(axis=0)\n",
    "\n",
    "            #Estimate priors.\n",
    "            self._priors[idx] = X_c.shape[0] / float(n_samples)\n",
    "\n",
    "        print(\"Mean: \", self._mean)\n",
    "        print(\"Variance: \", self._var)\n",
    "        print(\"Priors: \", self._priors)\n",
    "\n",
    "    def _calc_pdf(self, class_idx, X):\n",
    "        '''Calculates probability density for samples for class label class_idx'''\n",
    "\n",
    "        mean = self._mean[class_idx]\n",
    "        var = np.diag(self._var[class_idx])\n",
    "        z = np.power(2 * np.pi, X.shape[0]/2) * np.power(np.linalg.det(var), 1/2)\n",
    "        return (1/z) * np.exp(-(1/2)*(X - mean).T @ (np.linalg.inv(var)) @ (X - mean))\n",
    "\n",
    "    def _calc_prod_likelihood_prior(self, X):\n",
    "        '''Calculates product of likelihood and priors.'''\n",
    "\n",
    "        self._prod_likelihood_prior = np.zeros((X.shape[0], len(self._classes)), dtype=np.float64)\n",
    "\n",
    "        for x_idx, x in enumerate(X):\n",
    "            for idx, c in enumerate(self._classes):\n",
    "                self._prod_likelihood_prior[x_idx, c] = (np.log(self._calc_pdf(idx, x)) + np.log(self._priors[idx]))\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''Predicts class labels for each example'''\n",
    "        \n",
    "        self._calc_prod_likelihood_prior(X)\n",
    "\n",
    "        return np.argmax(self._prod_likelihood_prior, axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        '''Calculates probability of each example belonging to different classes.'''\n",
    "\n",
    "        self._calc_prod_likelihood_prior(X)\n",
    "\n",
    "        return np.exp(self._prod_likelihood_prior) / np.expand_dims(np.sum(np.exp(self._prod_likelihood_prior), axis = 1), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747557ed",
   "metadata": {},
   "source": [
    "| Concept            | Formula                                                                                                    | Code                            |\n",
    "| ------------------ | ---------------------------------------------------------------------------------------------------------- | ------------------------------- |\n",
    "| Feature likelihood | $(P(x_j \\mid y=c) = \\frac{1}{\\sqrt{2\\pi \\sigma^2_{jc}}} \\exp(-\\frac{(x_j-\\mu_{jc})^2}{2\\sigma^2_{jc}}))$     | `_calc_pdf()`                   |\n",
    "| Class prior        | $(\\pi_c = N_c/n)$                                                                                            | `self._priors[idx]`             |\n",
    "| Log-likelihood     | $(\\log P(x \\mid y=c) = \\sum_j [-\\frac12 \\log(2\\pi\\sigma^2_{jc}) - \\frac{(x_j-\\mu_{jc})^2}{2\\sigma^2_{jc}}])$ | `_calc_prod_likelihood_prior()` |\n",
    "| Posterior          | $(P(y=c \\mid x) = \\frac{P(x\\mid y=c)\\pi_c}{\\sum_{c'} P(x \\mid y=c')\\pi_{c'}})$                               | `predict_proba()`               |\n",
    "| Prediction         | $(\\hat{y} = \\arg\\max_c P(y=c \\mid x))$                                                                       | `predict()`                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f98a7a3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
