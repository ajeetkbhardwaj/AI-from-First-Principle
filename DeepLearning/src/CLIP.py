"""
Contrastive Language Image Pretraining(CLIP) helps the model to learn by
comparing pairs of images and text. It rewards the model(agent) when it
correctly matches an image with it's correponding text and penalizes it for
incorrect matches.

Hence, we can say that CLIP model trying to learn effective representatin of image and text into a
shared embedding space.
"""